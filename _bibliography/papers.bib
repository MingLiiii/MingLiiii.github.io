---
---

@misc{li2024mosaicitenhancinginstruction,
      title={Mosaic IT: Enhancing Instruction Tuning with Data Mosaics}, 
      abbr={arXiv},
      author={Ming Li and Pei Chen and Chenguang Wang and Hongyu Zhao and Yijun Liang and Yupeng Hou and Fuxiao Liu and Tianyi Zhou},
      year={2024},
      eprint={2405.13326},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.13326}, 
}

@misc{li2024superfilteringweaktostrongdatafiltering,
      title={Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning}, 
      abbr={ACL},
      author={Ming Li and Yong Zhang and Shwai He and Zhitao Li and Hongyu Zhao and Jianzong Wang and Ning Cheng and Tianyi Zhou},
      year={2024},
      eprint={2402.00530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00530}, 
}

@misc{li2024selectivereflectiontuningstudentselecteddata,
      title={Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning}, 
      abbr={ACL},
      author={Ming Li and Lichang Chen and Jiuhai Chen and Shwai He and Jiuxiang Gu and Tianyi Zhou},
      year={2024},
      eprint={2402.10110},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10110}, 
}

@misc{li2024llmsspeakdiversepeople,
      title={Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements}, 
      abbr={ACL},
      author={Ming Li and Jiuhai Chen and Lichang Chen and Tianyi Zhou},
      year={2024},
      eprint={2402.10614},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10614}, 
}

@misc{li2024quantityqualityboostingllm,
      title={From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning}, 
      abbr={NAACL},
      author={Ming Li and Yong Zhang and Zhitao Li and Jiuhai Chen and Lichang Chen and Ning Cheng and Jianzong Wang and Tianyi Zhou and Jing Xiao},
      year={2024},
      eprint={2308.12032},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.12032}, 
}

@misc{li2023reflectiontuningdatarecyclingimproves,
      title={Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning}, 
      abbr={NIPS Workshop},
      author={Ming Li and Lichang Chen and Jiuhai Chen and Shwai He and Heng Huang and Jiuxiang Gu and Tianyi Zhou},
      year={2023},
      eprint={2310.11716},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.11716}, 
}

@misc{xu2024surveyknowledgedistillationlarge,
      title={A Survey on Knowledge Distillation of Large Language Models}, 
      abbr={Survey},
      author={Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou},
      year={2024},
      eprint={2402.13116},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13116}, 
}
